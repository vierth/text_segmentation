# text_segmentation
An extremely basic jupyter notebook that inserts spaces between words in Chinese, Japanase, or Korean files using jieba (for Chinese), fugashi (for Japanese), or konlpy for Korean.

Simply place files to be tokenized in a folder in the same directory as the notebook, enter the name of the folder in the script, and specify the language. Produces a new folder with spaces inserted.
